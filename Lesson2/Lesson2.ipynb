{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Создание признакового пространства”\n",
    "\n",
    "Продолжим обработку данных с Твиттера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.__ Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "* Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "* Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "* Исключим стоп-слова с помощью stop_words='english'.\n",
    "* Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.read_pickle(\"./combine_df.pkl\")\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father', 'dysfunct', 'selfish', 'drag', 'kid', 'dysfunct', 'run']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet_stemmed'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_stemmed2</th>\n",
       "      <th>tweet_lemmatized2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
       "      <td>thank lyft credit use cause offer wheelchair v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>model love take time ur</td>\n",
       "      <td>model love take time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguid societi motiv</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...   \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                      tweet_stemmed2  \\\n",
       "0      father dysfunct selfish drag kid dysfunct run   \n",
       "1  thank lyft credit use caus offer wheelchair va...   \n",
       "2                                     bihday majesti   \n",
       "3                            model love take time ur   \n",
       "4                            factsguid societi motiv   \n",
       "\n",
       "                                   tweet_lemmatized2  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thank lyft credit use cause offer wheelchair v...  \n",
       "2                                     bihday majesty  \n",
       "3                            model love take time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet_stemmed2']=combine_df['tweet_stemmed'].apply(lambda x: \" \".join(x) )\n",
    "combine_df['tweet_lemmatized2']=combine_df['tweet_lemmatized'].apply(lambda x: \" \".join(x) )\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yeah good</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n",
       "0        0        0       0        0    0       0      0       0   0      0   \n",
       "1        0        0       0        0    0       0      0       0   0      0   \n",
       "2        0        0       0        0    0       0      0       0   0      0   \n",
       "3        0        0       0        0    0       0      0       0   0      0   \n",
       "4        0        0       0        0    0       0      0       0   0      0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...     ...  ..    ...   \n",
       "49154    0        0       0        0    0       0      0       0   0      0   \n",
       "49155    0        0       0        0    0       0      0       0   0      0   \n",
       "49156    0        0       0        0    0       0      0       0   0      0   \n",
       "49157    0        0       0        0    0       0      0       0   0      0   \n",
       "49158    0        0       0        0    0       0      0       0   0      0   \n",
       "\n",
       "       ...  yeah  yeah good  year  yesterday  yo  yoga  york  young  youtub  \\\n",
       "0      ...     0          0     0          0   0     0     0      0       0   \n",
       "1      ...     0          0     0          0   0     0     0      0       0   \n",
       "2      ...     0          0     0          0   0     0     0      0       0   \n",
       "3      ...     0          0     0          0   0     0     0      0       0   \n",
       "4      ...     0          0     0          0   0     0     0      0       0   \n",
       "...    ...   ...        ...   ...        ...  ..   ...   ...    ...     ...   \n",
       "49154  ...     0          0     0          0   0     0     0      0       0   \n",
       "49155  ...     0          0     0          0   0     0     0      0       0   \n",
       "49156  ...     0          0     0          0   0     0     0      0       0   \n",
       "49157  ...     0          0     0          0   0     0     0      0       0   \n",
       "49158  ...     0          0     0          0   0     0     0      0       0   \n",
       "\n",
       "       yr  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "49154   0  \n",
       "49155   0  \n",
       "49156   0  \n",
       "49157   0  \n",
       "49158   0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english', analyzer='word', binary=False,max_df=0.9, max_features=1000)\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words = count_vectorizer.fit_transform(combine_df['tweet_stemmed2'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0         0           0       0        0    0       0      0         0      0   \n",
       "1         0           0       0        0    0       0      0         0      0   \n",
       "2         0           0       0        0    0       0      0         0      0   \n",
       "3         0           0       0        0    0       0      0         0      0   \n",
       "4         0           0       0        0    0       0      0         0      0   \n",
       "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
       "49154     0           0       0        0    0       0      0         0      0   \n",
       "49155     0           0       0        0    0       0      0         0      0   \n",
       "49156     0           0       0        0    0       0      0         0      0   \n",
       "49157     0           0       0        0    0       0      0         0      0   \n",
       "49158     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "       adapt environment  ...  year  years  yes  yesterday  yo  yoga  york  \\\n",
       "0                      0  ...     0      0    0          0   0     0     0   \n",
       "1                      0  ...     0      0    0          0   0     0     0   \n",
       "2                      0  ...     0      0    0          0   0     0     0   \n",
       "3                      0  ...     0      0    0          0   0     0     0   \n",
       "4                      0  ...     0      0    0          0   0     0     0   \n",
       "...                  ...  ...   ...    ...  ...        ...  ..   ...   ...   \n",
       "49154                  0  ...     0      0    0          0   0     0     0   \n",
       "49155                  0  ...     0      0    0          0   0     0     0   \n",
       "49156                  0  ...     0      0    0          0   0     0     0   \n",
       "49157                  0  ...     0      0    0          0   0     0     0   \n",
       "49158                  0  ...     0      0    0          0   0     0     0   \n",
       "\n",
       "       young  youtube  yummy  \n",
       "0          0        0      0  \n",
       "1          0        0      0  \n",
       "2          0        0      0  \n",
       "3          0        0      0  \n",
       "4          0        0      0  \n",
       "...      ...      ...    ...  \n",
       "49154      0        0      0  \n",
       "49155      0        0      0  \n",
       "49156      0        0      0  \n",
       "49157      0        0      0  \n",
       "49158      0        0      0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words2 = count_vectorizer.fit_transform(combine_df['tweet_lemmatized2'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names2 = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words2.toarray(), columns = feature_names2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.__ Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "* Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "* Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "* Исключим стоп-слова с помощью stop_words='english'.\n",
    "* Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yeah good</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual   ad  adapt  \\\n",
       "0      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "1      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "2      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "3      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "4      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...     ...  ...    ...   \n",
       "49154  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49155  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49156  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49157  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49158  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "\n",
       "       ...  yeah  yeah good  year  yesterday   yo  yoga  york  young  youtub  \\\n",
       "0      ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "1      ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "2      ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "3      ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "4      ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "...    ...   ...        ...   ...        ...  ...   ...   ...    ...     ...   \n",
       "49154  ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "49155  ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "49156  ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "49157  ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "49158  ...   0.0        0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0   \n",
       "\n",
       "        yr  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "49154  0.0  \n",
       "49155  0.0  \n",
       "49156  0.0  \n",
       "49157  0.0  \n",
       "49158  0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', analyzer='word', binary=False,max_df=0.9, max_features=1000)\n",
    "values = tfidf_vectorizer.fit_transform(combine_df['tweet_stemmed2'])\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "1       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "2       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "3       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "4       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
       "49154   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "49155   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "49156   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "49157   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "49158   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "\n",
       "       adapt environment  ...  year  years  yes  yesterday   yo  yoga  york  \\\n",
       "0                    0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "1                    0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "2                    0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "3                    0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "4                    0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "...                  ...  ...   ...    ...  ...        ...  ...   ...   ...   \n",
       "49154                0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "49155                0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "49156                0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "49157                0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "49158                0.0  ...   0.0    0.0  0.0        0.0  0.0   0.0   0.0   \n",
       "\n",
       "       young  youtube  yummy  \n",
       "0        0.0      0.0    0.0  \n",
       "1        0.0      0.0    0.0  \n",
       "2        0.0      0.0    0.0  \n",
       "3        0.0      0.0    0.0  \n",
       "4        0.0      0.0    0.0  \n",
       "...      ...      ...    ...  \n",
       "49154    0.0      0.0    0.0  \n",
       "49155    0.0      0.0    0.0  \n",
       "49156    0.0      0.0    0.0  \n",
       "49157    0.0      0.0    0.0  \n",
       "49158    0.0      0.0    0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2 = tfidf_vectorizer.fit_transform(combine_df['tweet_lemmatized2'])\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names2 = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values2.toarray(), columns = feature_names2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.__ Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "* Тренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "* Установим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "* Используем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    min_count=2, #игнорировать все слова с частотой встречаемости меньше, чем это значение.\n",
    "    window=5, #размер контекстного окна, обозначает диапазон контекста.\n",
    "    size=200, # размер векторного представления слова (word embedding)\n",
    "    negative=10, # сколько неконтекстных слов учитывать в обучении\n",
    "    sg=1, #если 1, то используется реализация Skip-gram; если 0, то CBOW\n",
    "    hs=0,\n",
    "    workers=32,\n",
    "    seed=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Далее, требуется получить словарь:\n",
    "w2v_model.build_vocab(combine_df['tweet_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49159"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8990930, 11616500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А после уже можно обучить модель, используя метод train:\n",
    "w2v_model.train(combine_df['tweet_token'], total_examples=w2v_model.corpus_count, epochs=20, report_delay=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4.__ Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. То же самое попробуем со словом \"trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bihdaydinner', 0.5869648456573486),\n",
       " ('cookout', 0.5751090049743652),\n",
       " ('tacotuesday', 0.568770170211792),\n",
       " ('waterloo', 0.5660180449485779),\n",
       " ('shawarma', 0.5616282820701599),\n",
       " ('bolognese', 0.5601876974105835),\n",
       " ('iftar', 0.5577831864356995),\n",
       " ('burritos', 0.5554994940757751),\n",
       " ('hamburger', 0.5514653921127319),\n",
       " ('spaghetti', 0.5478783845901489)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"dinner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald', 0.5725772976875305),\n",
       " ('paladino', 0.533248245716095),\n",
       " ('unstable', 0.5207833051681519),\n",
       " ('trumptrain', 0.5187177658081055),\n",
       " ('conman', 0.5161398649215698),\n",
       " ('suppoer', 0.5120258927345276),\n",
       " ('melo', 0.5091587901115417),\n",
       " ('dumptrump', 0.5048690438270569),\n",
       " ('unfit', 0.5031173825263977),\n",
       " ('putins', 0.49655675888061523)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"trump\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.__ Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n",
    "Давайте проверим векторное представление любого слова из нашего корпуса, например \"food\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07321357,  0.09064846,  0.29303256, -0.05210466, -0.55896366,\n",
       "       -0.453702  , -0.690456  ,  0.25732926, -0.0291005 ,  0.31079084,\n",
       "       -0.15860215, -0.49337316, -0.2370369 , -0.88038945,  0.49703655,\n",
       "        0.04915431, -0.11136948, -0.06794264,  0.2380237 , -0.7085613 ,\n",
       "       -0.15785742,  0.8347053 , -0.45033267,  0.65797997,  0.13395655,\n",
       "       -0.61792284,  0.41257176, -0.4860222 , -0.6526082 , -0.00610965,\n",
       "       -0.56171435, -0.80201894, -1.081544  ,  0.0485823 ,  0.03568439,\n",
       "       -0.19220082, -0.06326626, -0.5774684 , -0.2496143 ,  0.4640255 ,\n",
       "       -0.13799909, -0.40848455, -0.6394649 ,  0.20107146, -0.5067535 ,\n",
       "        0.5602965 ,  0.48443782,  0.03114598, -0.08559838, -0.1190968 ,\n",
       "        0.4734044 , -0.783995  , -0.19776797,  0.696923  , -0.844875  ,\n",
       "        0.00623892,  0.29940382,  0.30976024, -0.03630346,  0.05780551,\n",
       "        0.04149044, -0.26867142, -0.090923  ,  0.11785357,  0.28567237,\n",
       "       -0.13560878, -0.5560514 , -0.4257982 ,  0.11473218, -0.10622259,\n",
       "        0.34719956,  0.6899515 ,  0.37662685,  0.5075774 ,  0.00154018,\n",
       "        0.23444125, -0.375503  , -0.00695082, -0.18847197, -0.5637474 ,\n",
       "       -0.04736396, -0.39697412, -0.27118552,  0.31738865, -0.06600812,\n",
       "       -0.11793885, -0.48877493,  0.10916895,  0.82625455,  0.208673  ,\n",
       "        0.4360051 , -0.09530685, -0.19099806, -0.9317527 ,  0.11746901,\n",
       "        0.81592673, -0.12301961, -0.38018447,  0.8510852 , -0.23918949,\n",
       "        0.15442064,  0.2500336 ,  0.290516  ,  0.66559607, -0.4836332 ,\n",
       "       -0.15662861, -0.50724524, -0.36016545,  0.05664587,  0.2377364 ,\n",
       "        0.24649487,  0.07970274,  0.43749815,  0.2392502 ,  0.09878723,\n",
       "        0.21081467, -1.132639  ,  0.2476965 , -0.00540613, -0.2006256 ,\n",
       "        0.41581032,  0.2084127 ,  0.14215426, -0.20024362,  0.35802737,\n",
       "        0.32524982,  0.03431058, -0.3014297 ,  0.9921915 , -0.22362995,\n",
       "       -0.848211  , -1.0974195 ,  0.09606841,  0.48576772, -0.5754813 ,\n",
       "       -0.08494993, -0.0746022 , -0.17270835, -0.31856456,  0.00804477,\n",
       "        0.6883728 , -0.04681258,  0.34757662, -0.31876022,  0.06411871,\n",
       "       -0.00829266, -0.00331625,  0.17725372, -0.793452  , -0.296847  ,\n",
       "       -0.39038625,  0.20011541,  0.10269521,  0.27815503,  0.3396381 ,\n",
       "       -0.5937268 ,  0.04926391, -0.1725215 , -0.07634947,  0.42328155,\n",
       "       -0.6987455 ,  0.09113549, -0.20502633,  0.2809908 ,  0.0099155 ,\n",
       "       -0.33814645, -0.45384732, -0.40749556, -0.35074532, -0.16256398,\n",
       "       -0.8333151 ,  0.931617  ,  0.2832436 ,  0.02995436,  0.09976919,\n",
       "       -0.062969  ,  0.1768292 ,  0.25026286,  0.13624418, -0.8231308 ,\n",
       "       -0.41885075,  0.96586734, -0.21776173, -0.7407752 , -0.11825994,\n",
       "        0.09799267,  0.43458557,  0.27770752, -0.13589692, -0.13647695,\n",
       "       -0.2910215 ,  0.0861929 ,  0.41596845, -0.6171396 , -0.30856144,\n",
       "       -0.18222634,  0.4363906 , -0.44365957, -0.140922  ,  0.35400516],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv[\"food\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.word_vec(\"food\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6.__ Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07321357,  0.09064846,  0.29303256, -0.05210466, -0.55896366,\n",
       "        -0.453702  , -0.690456  ,  0.25732926, -0.0291005 ,  0.31079084,\n",
       "        -0.15860215, -0.49337316, -0.2370369 , -0.88038945,  0.49703655,\n",
       "         0.04915431, -0.11136948, -0.06794264,  0.2380237 , -0.7085613 ,\n",
       "        -0.15785742,  0.8347053 , -0.45033267,  0.65797997,  0.13395655,\n",
       "        -0.61792284,  0.41257176, -0.4860222 , -0.6526082 , -0.00610965,\n",
       "        -0.56171435, -0.80201894, -1.081544  ,  0.0485823 ,  0.03568439,\n",
       "        -0.19220082, -0.06326626, -0.5774684 , -0.2496143 ,  0.4640255 ,\n",
       "        -0.13799909, -0.40848455, -0.6394649 ,  0.20107146, -0.5067535 ,\n",
       "         0.5602965 ,  0.48443782,  0.03114598, -0.08559838, -0.1190968 ,\n",
       "         0.4734044 , -0.783995  , -0.19776797,  0.696923  , -0.844875  ,\n",
       "         0.00623892,  0.29940382,  0.30976024, -0.03630346,  0.05780551,\n",
       "         0.04149044, -0.26867142, -0.090923  ,  0.11785357,  0.28567237,\n",
       "        -0.13560878, -0.5560514 , -0.4257982 ,  0.11473218, -0.10622259,\n",
       "         0.34719956,  0.6899515 ,  0.37662685,  0.5075774 ,  0.00154018,\n",
       "         0.23444125, -0.375503  , -0.00695082, -0.18847197, -0.5637474 ,\n",
       "        -0.04736396, -0.39697412, -0.27118552,  0.31738865, -0.06600812,\n",
       "        -0.11793885, -0.48877493,  0.10916895,  0.82625455,  0.208673  ,\n",
       "         0.4360051 , -0.09530685, -0.19099806, -0.9317527 ,  0.11746901,\n",
       "         0.81592673, -0.12301961, -0.38018447,  0.8510852 , -0.23918949,\n",
       "         0.15442064,  0.2500336 ,  0.290516  ,  0.66559607, -0.4836332 ,\n",
       "        -0.15662861, -0.50724524, -0.36016545,  0.05664587,  0.2377364 ,\n",
       "         0.24649487,  0.07970274,  0.43749815,  0.2392502 ,  0.09878723,\n",
       "         0.21081467, -1.132639  ,  0.2476965 , -0.00540613, -0.2006256 ,\n",
       "         0.41581032,  0.2084127 ,  0.14215426, -0.20024362,  0.35802737,\n",
       "         0.32524982,  0.03431058, -0.3014297 ,  0.9921915 , -0.22362995,\n",
       "        -0.848211  , -1.0974195 ,  0.09606841,  0.48576772, -0.5754813 ,\n",
       "        -0.08494993, -0.0746022 , -0.17270835, -0.31856456,  0.00804477,\n",
       "         0.6883728 , -0.04681258,  0.34757662, -0.31876022,  0.06411871,\n",
       "        -0.00829266, -0.00331625,  0.17725372, -0.793452  , -0.296847  ,\n",
       "        -0.39038625,  0.20011541,  0.10269521,  0.27815503,  0.3396381 ,\n",
       "        -0.5937268 ,  0.04926391, -0.1725215 , -0.07634947,  0.42328155,\n",
       "        -0.6987455 ,  0.09113549, -0.20502633,  0.2809908 ,  0.0099155 ,\n",
       "        -0.33814645, -0.45384732, -0.40749556, -0.35074532, -0.16256398,\n",
       "        -0.8333151 ,  0.931617  ,  0.2832436 ,  0.02995436,  0.09976919,\n",
       "        -0.062969  ,  0.1768292 ,  0.25026286,  0.13624418, -0.8231308 ,\n",
       "        -0.41885075,  0.96586734, -0.21776173, -0.7407752 , -0.11825994,\n",
       "         0.09799267,  0.43458557,  0.27770752, -0.13589692, -0.13647695,\n",
       "        -0.2910215 ,  0.0861929 ,  0.41596845, -0.6171396 , -0.30856144,\n",
       "        -0.18222634,  0.4363906 , -0.44365957, -0.140922  ,  0.35400516]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv[\"food\"].reshape((1, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49159"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_df['tweet_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'father',\n",
       " 'is',\n",
       " 'dysfunctional',\n",
       " 'and',\n",
       " 'is',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'he',\n",
       " 'drags',\n",
       " 'his',\n",
       " 'kids',\n",
       " 'into',\n",
       " 'his',\n",
       " 'dysfunction',\n",
       " 'run']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet_token'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_embedding(lst_tokens, model):\n",
    "    vec = np.zeros([model.vector_size], dtype='float32')\n",
    "    cnt = 0\n",
    "    for word in lst_tokens:\n",
    "        if word in model:\n",
    "            vec += model[word]\n",
    "            cnt +=1\n",
    "    if cnt>0:\n",
    "        vec = vec / cnt \n",
    "    #vec = vec.reshape((1, model.vector_size))\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sych_\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n",
      "c:\\users\\sych_\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "wordvec_df =combine_df['tweet_token'].apply(lambda x: get_phrase_embedding(x, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20240115, -0.12998451,  0.23199609,  0.3623055 , -0.01672714,\n",
       "       -0.13067836,  0.19958563,  0.02066224, -0.10943821,  0.07062028,\n",
       "        0.06663352, -0.05373319, -0.11695334, -0.1394439 ,  0.2422918 ,\n",
       "       -0.12932473, -0.27396408, -0.22788855, -0.08536243,  0.05504399,\n",
       "       -0.1047062 ,  0.09737012, -0.1569722 ,  0.06702345,  0.065232  ,\n",
       "       -0.064215  ,  0.26439652, -0.04006628, -0.00599399, -0.28296804,\n",
       "       -0.0624992 ,  0.17023827,  0.07884469,  0.17737813,  0.170791  ,\n",
       "        0.00143625, -0.0670465 ,  0.10097753, -0.16064347,  0.19236583,\n",
       "        0.14340179,  0.11838964, -0.1369677 ,  0.1210659 ,  0.04351616,\n",
       "       -0.00965909, -0.14824207, -0.2224106 ,  0.09145845, -0.11312795,\n",
       "       -0.07935776,  0.12238423, -0.06747578,  0.04522596, -0.19623275,\n",
       "        0.18265356,  0.00960148,  0.24298458, -0.10631742, -0.5050434 ,\n",
       "        0.15956366, -0.00359675,  0.20793365, -0.32664245,  0.09791937,\n",
       "       -0.23771936, -0.18109201,  0.03383457, -0.02655108,  0.04765339,\n",
       "        0.13708961,  0.08575229,  0.07975236,  0.08092119,  0.07072637,\n",
       "        0.00869784, -0.11603327,  0.4046648 ,  0.03525089, -0.44320357,\n",
       "       -0.11404831,  0.071814  ,  0.0935139 , -0.04520164, -0.00664845,\n",
       "        0.00473046,  0.26052073,  0.05624012,  0.41122386, -0.13563111,\n",
       "       -0.00373122, -0.07359236, -0.07149854, -0.2663889 ,  0.29139143,\n",
       "       -0.18379454,  0.2119345 , -0.01078203,  0.4107935 ,  0.21931797,\n",
       "       -0.19030282, -0.20286448,  0.04332601,  0.01930265, -0.24462208,\n",
       "        0.03263659, -0.16087018, -0.2807886 ,  0.06437065, -0.02722033,\n",
       "        0.04592688, -0.01462613, -0.0654795 , -0.08192828, -0.34054852,\n",
       "        0.07074765, -0.0912305 ,  0.14283127,  0.05614828, -0.08703656,\n",
       "        0.06640615,  0.04740432, -0.3214988 , -0.01957828, -0.1483312 ,\n",
       "        0.22304633,  0.24805945,  0.12454384,  0.03815244,  0.0278854 ,\n",
       "       -0.18392274, -0.13795346, -0.11664172,  0.20781994,  0.06122689,\n",
       "        0.2638309 ,  0.07951054, -0.1799191 ,  0.34881413,  0.03537054,\n",
       "        0.04464757, -0.21541256,  0.14291771, -0.01713583,  0.00647728,\n",
       "        0.07201676,  0.21107104, -0.08191361, -0.02603422, -0.331977  ,\n",
       "       -0.20998323, -0.04799762,  0.13930282,  0.05307226,  0.086088  ,\n",
       "        0.19435756, -0.29710582,  0.42919233, -0.1884406 ,  0.01032716,\n",
       "        0.10803109, -0.10076226, -0.16736084,  0.13526405,  0.12889785,\n",
       "       -0.01005438, -0.44503748, -0.26030222, -0.03500528,  0.09959651,\n",
       "       -0.2315794 ,  0.02624949,  0.10848065,  0.03846434,  0.07335681,\n",
       "       -0.19438253,  0.23032434,  0.10363645,  0.0350621 , -0.23851684,\n",
       "       -0.28867745,  0.14711198, -0.16909572,  0.07402122,  0.1942621 ,\n",
       "        0.18708366, -0.08275627,  0.16004851,  0.09633503,  0.11769564,\n",
       "       -0.35322103, -0.03394519,  0.00456327, -0.07028233, -0.13674363,\n",
       "       -0.01015409, -0.35384434, -0.04875978,  0.16585465, -0.1950607 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df =np.hstack(wordvec_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9831800,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df = wordvec_df.reshape((49159, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 200)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20240115, -0.12998451,  0.23199609,  0.3623055 , -0.01672714,\n",
       "       -0.13067836,  0.19958563,  0.02066224, -0.10943821,  0.07062028,\n",
       "        0.06663352, -0.05373319, -0.11695334, -0.1394439 ,  0.2422918 ,\n",
       "       -0.12932473, -0.27396408, -0.22788855, -0.08536243,  0.05504399,\n",
       "       -0.1047062 ,  0.09737012, -0.1569722 ,  0.06702345,  0.065232  ,\n",
       "       -0.064215  ,  0.26439652, -0.04006628, -0.00599399, -0.28296804,\n",
       "       -0.0624992 ,  0.17023827,  0.07884469,  0.17737813,  0.170791  ,\n",
       "        0.00143625, -0.0670465 ,  0.10097753, -0.16064347,  0.19236583,\n",
       "        0.14340179,  0.11838964, -0.1369677 ,  0.1210659 ,  0.04351616,\n",
       "       -0.00965909, -0.14824207, -0.2224106 ,  0.09145845, -0.11312795,\n",
       "       -0.07935776,  0.12238423, -0.06747578,  0.04522596, -0.19623275,\n",
       "        0.18265356,  0.00960148,  0.24298458, -0.10631742, -0.5050434 ,\n",
       "        0.15956366, -0.00359675,  0.20793365, -0.32664245,  0.09791937,\n",
       "       -0.23771936, -0.18109201,  0.03383457, -0.02655108,  0.04765339,\n",
       "        0.13708961,  0.08575229,  0.07975236,  0.08092119,  0.07072637,\n",
       "        0.00869784, -0.11603327,  0.4046648 ,  0.03525089, -0.44320357,\n",
       "       -0.11404831,  0.071814  ,  0.0935139 , -0.04520164, -0.00664845,\n",
       "        0.00473046,  0.26052073,  0.05624012,  0.41122386, -0.13563111,\n",
       "       -0.00373122, -0.07359236, -0.07149854, -0.2663889 ,  0.29139143,\n",
       "       -0.18379454,  0.2119345 , -0.01078203,  0.4107935 ,  0.21931797,\n",
       "       -0.19030282, -0.20286448,  0.04332601,  0.01930265, -0.24462208,\n",
       "        0.03263659, -0.16087018, -0.2807886 ,  0.06437065, -0.02722033,\n",
       "        0.04592688, -0.01462613, -0.0654795 , -0.08192828, -0.34054852,\n",
       "        0.07074765, -0.0912305 ,  0.14283127,  0.05614828, -0.08703656,\n",
       "        0.06640615,  0.04740432, -0.3214988 , -0.01957828, -0.1483312 ,\n",
       "        0.22304633,  0.24805945,  0.12454384,  0.03815244,  0.0278854 ,\n",
       "       -0.18392274, -0.13795346, -0.11664172,  0.20781994,  0.06122689,\n",
       "        0.2638309 ,  0.07951054, -0.1799191 ,  0.34881413,  0.03537054,\n",
       "        0.04464757, -0.21541256,  0.14291771, -0.01713583,  0.00647728,\n",
       "        0.07201676,  0.21107104, -0.08191361, -0.02603422, -0.331977  ,\n",
       "       -0.20998323, -0.04799762,  0.13930282,  0.05307226,  0.086088  ,\n",
       "        0.19435756, -0.29710582,  0.42919233, -0.1884406 ,  0.01032716,\n",
       "        0.10803109, -0.10076226, -0.16736084,  0.13526405,  0.12889785,\n",
       "       -0.01005438, -0.44503748, -0.26030222, -0.03500528,  0.09959651,\n",
       "       -0.2315794 ,  0.02624949,  0.10848065,  0.03846434,  0.07335681,\n",
       "       -0.19438253,  0.23032434,  0.10363645,  0.0350621 , -0.23851684,\n",
       "       -0.28867745,  0.14711198, -0.16909572,  0.07402122,  0.1942621 ,\n",
       "        0.18708366, -0.08275627,  0.16004851,  0.09633503,  0.11769564,\n",
       "       -0.35322103, -0.03394519,  0.00456327, -0.07028233, -0.13674363,\n",
       "       -0.01015409, -0.35384434, -0.04875978,  0.16585465, -0.1950607 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
